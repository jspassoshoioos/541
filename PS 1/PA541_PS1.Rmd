---
title: "541 PS1"
author: "Jake da Silva Passos-Hoioos"
date: "2/4/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Details 

Name: Jake da Silva Passos-Hoioos
Class: PA 541 - Advanced Data Analysis
 
# PART ONE - Data Wrangling

Read in the ‘fatalities’ data.  The data come from the US Department of Transportation Fatal Accident Reporting System.
Total vehicle miles traveled annually by state was obtained from the Department of Transportation. Personal income was obtained from the US Bureau of Economic Analysis,
and the unemployment rate was obtained from the US Bureau of Labor Statistics. You can read in the data using following:  fatal = read_csv("Fatalities.csv") 
Names and descriptions of those variables are below.

	state - state.
	year - year.
	spirits - Spirits consumption.
	unemp - Unemployment rate.
	income - Per capita personal income in 1987 dollars.
	emppop - Employment/population ratio.
	beertax -  Tax on case of beer.
	baptist - Percent of southern baptist.
	mormon - Percent of mormon.
	drinkage - Minimum legal drinking age.
	dry -  Percent residing in “dry” countries.
	youngdrivers - Percent of drivers aged 15--24.
	miles - Average miles per driver.
	breath - Preliminary breath test law?
	jail - Mandatory jail sentence?
	service- Mandatory community service?
	fatal - Number of vehicle fatalities.
	nfatal - Number of night-time vehicle fatalities.
	sfatal - Number of single vehicle fatalities.
	fatal1517 - Number of vehicle fatalities, 15--17 year olds.
	nfatal1517 -  Number of night-time vehicle fatalities, 15--17 year olds.
	fatal1820 -  Number of vehicle fatalities, 18--20 year olds.
	nfatal1820 - Number of night-time vehicle fatalities, 18--20 year olds.
	fatal2124 - Number of vehicle fatalities, 21--24 year olds.
	nfatal2124 - Number of night-time vehicle fatalities, 21--24 year olds.
	afatal - Number of alcohol-involved vehicle fatalities.
	pop - Population.
	pop1517 -  Population, 15--17 year olds.
	pop1820 -  Population, 18--20 year olds.
	pop2124 - Population, 21--24 year olds.
	milestot - Total vehicle miles (millions).
	unempus - US unemployment rate.
	emppopus -  US employment/population ratio.
	gsp - GSP rate of change.

```{r libaries and data}
# Setting WD
file_loc <- '~/../Documents/GitHub/541/PS 1/'
setwd(file_loc)

# libraries 

library(tidyverse)

# data read

fatality <- read_csv(paste0(file_loc, "/Fatalities.csv"))

glimpse(fatality) # check variables 

```


## QUESTION 1 (20pts)
The following will require you to use the tools and verbs we have learned to wrangle data. The results of these tasks will produce a tibble. You only need to copy and paste the tibble itself (what R reports) and not all of the variables or observations (i.e., don’t copy out the whole dataset).
First, select a handful of variables to focus on and remove the others. 
	Create a new dataset, call it fatality2, that contains only the following variables: fatal, state, year, spirits, unemp, income, dry, pop, and miles. Use this dataset for all steps below. (5pts)

```{r Q1 P1}
fatality2 <- fatality %>% 
  select(fatal, state, year, spirits, unemp, income, dry, pop, miles)

fatality2 

dim(fatality2) # Should be 336 X 9 

```

	For each year available in the dataset (i.e., 1982 – 1988), how many total fatalities were there in each of those years? (3pts)
	
```{r Q1 P2}

# Call a tibble that summarises fatal within each year (grouping is year)

fatality2 %>% 
  group_by(year) %>% 
  summarise(total_fatalities = sum(fatal))

```


	Which state had the largest number of fatalities in 1982? (2pts)

```{r Q1 P3}

# First need to filter just 1982 and then arrange fatal in desc. order

fatality2 %>% 
  filter(year == 1982) %>% 
  arrange(desc(fatal))

# So California had the most number of fatalities in 1982

```

	Which states in which years had more than 1,000 fatalities and more than 20% of its population residing in dry counties. (5pts)
	
```{r Q1 P4}

# Mostly filtering here, need to specify value ranges for fatal and dry 

fatality2 %>% 
  filter(fatal > 1000, 
         dry > 20)

# Only two states, Alabama and North Carolina, meet those conditions in 1986-1988 and 1982-1988 respectively

```


	What is the average number of fatalities in each state? (5pts)
	
```{r Q1 P5}
# Similar to the previous summarise but now grouping by state instead of year, and calculating average not sum. 

fatality2 %>% 
  group_by(state) %>% 
  summarise(avg_fatal = mean(fatal))

```


## QUESTION 2 (5 pts)
Create a new variable, ‘fatal.cat’ that breaks the continuous variable fatal down into three categories: (i) 0 - 300, (ii) >300 - 1000, (iii) >1000. Please label the categories “low”, “mid”, “high”. Set this new variable to be a factor.
What is the mean of miles in each of the fatal categories?

```{r Q2}

fatality2 <- fatality2 %>% 
  mutate( fatal.cat = as.factor(
    case_when( 
      fatal >= 0 & fatal <=300 ~ "low",
      fatal > 300 & fatal <= 1000 ~ "mid", 
      fatal > 1000 ~ "high")
  )
  )

fatality2
```


# PART TWO
This section will focus on simple regression. For part 2, limit the fatality2 data from above to only the year 1987. So, to begin part 2, create this new dataset and call it fatality3.

```{r Begin Part 2}

fatality3 <- fatality2 %>% 
  filter(year == 1987)

fatality3

```


## QUESTION 3 (10 pts)
Using the newly created fatality3 dataset, test the correlation between miles and fatal. What are your findings (i.e., what is the size of the correlation and is it significant)?
```{r}

lm1 <- lm(fatal ~ miles, data = fatality3)

summary(lm1)

```

These results tell us that if the average number of miles is zero, then we would expect there to be approximately 2,518 deaths a year, and for that number to decrease by -0.18 with each additional average mile. This means that we would expect the number of fatalities to **decrease** (i.e., fatalities are negatively correlated with miles) as the average number of miles per driver increases, which intuitively makes sense, since we would expect drivers that have driven more on average to get into accidents less frequently. 

That being said, the correlation coefficient for miles is **not statistically significant** as the p-value is 0.169, which is greater than .05. Given this high p-value, which indicates a ~17% chance that the observed trend is simply due to natural variation in the data. Since that chance is greater than 5%, we fail to find that the correlation between miles and fatalities is statistically significant. 

## QUESTION 4 (20 pts)
Create a new population variable, that is population in 100,000s. Call the new variable pop_100k. Run a simple linear regression predicting fatal from pop.100k.
```{r Q4 P1}

fatality3 <- fatality3 %>% 
  mutate(pop_100k = pop / 100000)

fatality3

lm2 <- lm(fatal ~ pop_100k, data = fatality3)
summary(lm2)
```

	Interpret the estimates of the slope and intercept coefficients in the context of the problem. (10pts)

The interpretation of the linear regression is as follows: 

When the population (in 100s of thousands) is 0, our model predicts that there would still be 66.84 fatalities, which is seemingly illogical (if population is 0 then we would expect 0 fatalities), but the intercept is not statistically significant, so this does not mean much in the broader interpretation of our model, beyond the fact that it does not accurately predict the number of fatalities when population is 0. 

What is statistically significant at a very high level (although not unsurprisingly) is the slope of our regression model (i.e. the correlation coefficient of our only IV, pop_100k), which means that for each increase in 100,000 people (remember our population unit is 100,000s of thousands), we would expect there to be an increase in fatalities by 17.79, meaning that population and vehicle fatalities are **positively correlated** so that as population increases, so do the number of fatalities.  

	What is the percentage of variation in fatal explained by pop_100k? (5pts)

That would be the R squared value, which in this case is 92%, so 92% of the data is explained by variation in population. 


	Predict the number of fatalities in a state if the population was 8 million. (5pts)
	
```{r}

# Remember that our model is just, fatal = 66.8468 + 19.7922(pop_100k) 

q4_ans <- as.numeric(66.9468 + 19.7922*(8000000/100000))

q4_ans

```

Our model predicts that with a population of 8 million (80 in pop_100k terms) would have approximately **1,650.323 fatalities** in 1987


## QUESTION 5 (10 pts)
Which state has the largest negative residual in our model from question 5? Which state has the largest positive residual? What do these large positive and large negative residuals mean within the context of our data and model.

```{r Q5}
fatality3 %>% 
  mutate(pred_value = predict(lm2), 
         resid = resid(lm2)) %>% 
  select(everything(), fatal, pred_value, resid) %>% 
  arrange(desc(resid))
```

New York has greatest negative residual, while Florida had the greatest positive residual. Since the residual is the difference between the observed value and expected value, a high positive residual means that the observed value was significantly higher than the predicted/expected value of the model. Meanwhile, a low negative residual (i.e., a large negative number), indicates the opposite, that the observed value was signficiantly smaller than what the model predicted it to be. 

In either case, the further the residual is from 0, the bigger the difference between what is actually observed and what is predicted by the model, while the sign of the residual indicates the directionality of the error. In context this means that Florida and New York are the worst predicted states by our model for fatalities, with New York's fatalities being the greatest overcount (prediction > observed, negative residual), and Flordia's being the greatest undercount (prediction < observed, positive residual). Put differently, the model thought that New York would have much more fatalities than what it actually experienced, while the model thought Flordia would have much less fatalities than what it actually experienced. 

## QUESTION 6 (15 pts)

Run another regression model with fatal as the dependent variable and pop_100k, miles, and dry as the independent variables.

```{r}
lm3 <- lm(fatal ~ pop_100k + miles + dry, data = fatality3)
summary(lm3)

```


	What percentage of the variation in the dependent variable is explained by the independent variables?
	
**94% of the variation** as indicated by the R-squared value

	Ignoring whether the predictor is significant or not, interpret the coefficient estimates for each predictor. Be specific when discussing the relationship.


	How do we interpret the p-value for dry?

	By how much did our R-squared increase from our initial model that only included pop_100k as a predictor?

## QUESTION 7 (15 pts)
Run the following two models and compare the difference in the size and direction of the coefficient on miles. What is happening here? Can we trust the estimate of the effect of miles in the first model?
Y_i=β_0+β_1 miles_i+e_i
Y_i=β_0+β_1 miles_i+β_2 pop_100k_i+e_i





## QUESTION 8 (5 pts)

	Define randomness. Give an example of randomness that might appear in data analysis.


	Define endogeneity. Give an example of how endogeneity might appear in data analysis. 

